{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c37ba0-f853-41b0-93b3-dad8be052881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec9f47-6e22-4d96-b598-0491f1c4aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name:- Shamal Kadbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c583aa-3b69-440f-b043-9d6f1c55dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e45690-53cd-4a1e-8c88-e5320cd34723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('Beans_Multiclass_Classification.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649b17d-d1e6-43d8-9e60-97affbde4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d56b1b-c95a-4644-97b8-4f6174662897",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1349eaf-ae1c-4d58-9777-612c8c2b92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45551729-1008-4b98-8a1f-076158325b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a431d-7958-46e3-a76e-debba4f91329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Class' is your target column\n",
    "feature_columns = [col for col in df.columns if col != 'Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5d5eb-8dda-4348-af2c-a7c96330bd6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ac3cb-f475-4ded-acd6-1579bf157e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='Class')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "class_counts = df['Class'].value_counts(normalize=True)\n",
    "print(\"Class proportions:\\n\", class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc1f2d-d4ec-4f6d-b04f-f7c2671a24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[feature_columns].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ce5b93-38ab-4cc4-8b4a-a66166ae16bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, vars=feature_columns[:5], hue='Class', diag_kind='kde')  # Limit to a few features\n",
    "plt.suptitle(\"Multivariate Relationships by Class\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03352c35-857c-4fe6-84b4-a2f956ff7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histograms for all numerical features\n",
    "df.hist(figsize=(18, 14), bins=20, edgecolor='black')\n",
    "plt.suptitle(\"Feature Distributions (Histograms)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fbd82-9c15-4cc2-a122-feed240ba48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for all numerical features\n",
    "plt.figure(figsize=(18, 12))\n",
    "df.drop(\"Class\", axis=1).boxplot(rot=90)\n",
    "plt.title(\"Feature Distributions (Boxplots)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a72071-b8e1-446b-af7f-51eedc5136bd",
   "metadata": {},
   "source": [
    "\n",
    "#### Observations:-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94926397-cd7a-4b26-928a-4805a5622ec9",
   "metadata": {},
   "source": [
    "#####  1. Feature Distribution Insights:-\n",
    "##### Several features show skewness (e.g., Area, MajorAxisLength) â€” consider log transformation.\n",
    "##### Outliers detected in features like Eccentricity and Extent via boxplots â€” flag for handling or justification.\n",
    "\n",
    "##### 2. Class Distribution:-\n",
    "##### Data is imbalanced across classes â€” majority class (SEKER) dominates.\n",
    "##### Minority classes (BARBUNYA, HOROZ) may need oversampling (e.g., SMOTE) or class-weight adjustment in model.\n",
    "\n",
    "##### 3. Feature Correlations:-\n",
    "##### Strong positive correlation between Perimeter and MajorAxisLength (r > 0.85).\n",
    "##### Negative correlation between Eccentricity and Compactness suggests non-linear relationships.\n",
    "\n",
    "##### 4. Multivariate Relationships:-\n",
    "##### Pairplot shows clear class separation along AspectRatio and Solidity.\n",
    "##### Some features show overlapping distributions across classes â€” might require dimensionality reduction or interaction terms.\n",
    "\n",
    "##### 5. Implications for Modeling:-\n",
    "##### Imbalance indicates a need for stratified sampling and evaluation via metrics like F1-score or AUC.\n",
    "##### Redundant features could be dropped or used in PCA for compact representations.\n",
    "##### Consider feature scaling for models sensitive to magnitude (e.g., SVM, KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a664dc2-9aec-419e-956a-db76d1ee2054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier counts:\n",
      " Area               483\n",
      "Perimeter          404\n",
      "MajorAxisLength    316\n",
      "MinorAxisLength    508\n",
      "AspectRation        15\n",
      "Eccentricity       125\n",
      "ConvexArea         483\n",
      "EquivDiameter      465\n",
      "Extent             135\n",
      "Solidity           238\n",
      "roundness           74\n",
      "Compactness          1\n",
      "ShapeFactor1        59\n",
      "ShapeFactor2         5\n",
      "ShapeFactor3         8\n",
      "ShapeFactor4       242\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import zscore\n",
    "z_scores = zscore(df[feature_columns])\n",
    "outliers = (np.abs(z_scores) > 3)\n",
    "print(\"Outlier counts:\\n\", outliers.sum(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b1502cd-fc58-4f88-9492-4b9e0729f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area: 551 outliers\n",
      "Perimeter: 500 outliers\n",
      "MajorAxisLength: 379 outliers\n",
      "MinorAxisLength: 569 outliers\n",
      "AspectRation: 473 outliers\n",
      "Eccentricity: 843 outliers\n",
      "ConvexArea: 550 outliers\n",
      "EquivDiameter: 526 outliers\n",
      "Extent: 275 outliers\n",
      "Solidity: 778 outliers\n",
      "roundness: 91 outliers\n",
      "Compactness: 109 outliers\n",
      "ShapeFactor1: 533 outliers\n",
      "ShapeFactor2: 0 outliers\n",
      "ShapeFactor3: 195 outliers\n",
      "ShapeFactor4: 767 outliers\n"
     ]
    }
   ],
   "source": [
    "for col in feature_columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f'{col}: {outliers.shape[0]} outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d4d7296-cf81-459f-a0ac-efac946d5d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)   # Features\n",
    "y = df['Class']                # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce28c004-d5a2-4b72-a8b3-1e72b63c50e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewed features:\n",
      " Area               2.952931\n",
      "ConvexArea         2.941821\n",
      "MinorAxisLength    2.238211\n",
      "EquivDiameter      1.948958\n",
      "Perimeter          1.626124\n",
      "MajorAxisLength    1.357815\n",
      "Eccentricity      -1.062824\n",
      "Solidity          -2.550093\n",
      "ShapeFactor4      -2.759483\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check skewness\n",
    "skewed_features = X.skew().sort_values(ascending=False)\n",
    "print(\"Skewed features:\\n\", skewed_features[abs(skewed_features) > 1])\n",
    "\n",
    "# Apply log1p transformation to highly skewed features (if needed)\n",
    "X[skewed_features[abs(skewed_features) > 1].index] = np.log1p(X[skewed_features[abs(skewed_features) > 1].index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d67147-93ae-401d-8d2c-0f30e5082798",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "524fcef2-1533-4d76-a7f1-0267382c6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a893409-ce61-45af-ac41-e16265d3f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (10888, 16)\n",
      "Test size: (2723, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af4b6b2-3340-460d-a498-8b8b2d66d932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression\n",
      "Accuracy: 0.9221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.96      0.89      0.92       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.93      0.94      0.93       326\n",
      "    DERMASON       0.93      0.91      0.92       709\n",
      "       HOROZ       0.96      0.95      0.96       386\n",
      "       SEKER       0.93      0.96      0.94       406\n",
      "        SIRA       0.85      0.88      0.87       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.94      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n",
      "\n",
      " Decision Tree\n",
      "Accuracy: 0.895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.90      0.90      0.90       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.93      0.91      0.92       326\n",
      "    DERMASON       0.88      0.89      0.89       709\n",
      "       HOROZ       0.94      0.93      0.93       386\n",
      "       SEKER       0.91      0.95      0.93       406\n",
      "        SIRA       0.82      0.80      0.81       527\n",
      "\n",
      "    accuracy                           0.89      2723\n",
      "   macro avg       0.91      0.91      0.91      2723\n",
      "weighted avg       0.89      0.89      0.89      2723\n",
      "\n",
      "\n",
      " Random Forest\n",
      "Accuracy: 0.9225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.93      0.89      0.91       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.94      0.94      0.94       326\n",
      "    DERMASON       0.91      0.92      0.92       709\n",
      "       HOROZ       0.97      0.96      0.96       386\n",
      "       SEKER       0.94      0.96      0.95       406\n",
      "        SIRA       0.87      0.86      0.87       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.94      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n",
      "\n",
      " K-Nearest Neighbors\n",
      "Accuracy: 0.917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.94      0.88      0.91       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.92      0.94      0.93       326\n",
      "    DERMASON       0.91      0.92      0.91       709\n",
      "       HOROZ       0.96      0.95      0.95       386\n",
      "       SEKER       0.95      0.94      0.95       406\n",
      "        SIRA       0.85      0.87      0.86       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.93      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n",
      "\n",
      " Support Vector Machine\n",
      "Accuracy: 0.9229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.89      0.92       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.93      0.95      0.94       326\n",
      "    DERMASON       0.92      0.92      0.92       709\n",
      "       HOROZ       0.96      0.96      0.96       386\n",
      "       SEKER       0.94      0.95      0.94       406\n",
      "        SIRA       0.86      0.87      0.87       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.94      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n",
      "\n",
      " Naive Bayes\n",
      "Accuracy: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.89      0.79      0.84       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.86      0.92      0.89       326\n",
      "    DERMASON       0.94      0.86      0.89       709\n",
      "       HOROZ       0.95      0.95      0.95       386\n",
      "       SEKER       0.92      0.94      0.93       406\n",
      "        SIRA       0.80      0.89      0.85       527\n",
      "\n",
      "    accuracy                           0.90      2723\n",
      "   macro avg       0.91      0.91      0.91      2723\n",
      "weighted avg       0.90      0.90      0.90      2723\n",
      "\n",
      "\n",
      " AdaBoost\n",
      "Accuracy: 0.6306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.00      0.00      0.00       265\n",
      "      BOMBAY       0.00      0.00      0.00       104\n",
      "        CALI       0.46      0.99      0.62       326\n",
      "    DERMASON       0.63      0.95      0.76       709\n",
      "       HOROZ       0.97      0.65      0.78       386\n",
      "       SEKER       0.91      0.21      0.34       406\n",
      "        SIRA       0.78      0.72      0.75       527\n",
      "\n",
      "    accuracy                           0.63      2723\n",
      "   macro avg       0.54      0.50      0.47      2723\n",
      "weighted avg       0.64      0.63      0.58      2723\n",
      "\n",
      "\n",
      " Gradient Boosting\n",
      "Accuracy: 0.9225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.89      0.92       265\n",
      "      BOMBAY       1.00      1.00      1.00       104\n",
      "        CALI       0.94      0.94      0.94       326\n",
      "    DERMASON       0.91      0.93      0.92       709\n",
      "       HOROZ       0.96      0.95      0.95       386\n",
      "       SEKER       0.95      0.96      0.95       406\n",
      "        SIRA       0.86      0.86      0.86       527\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.94      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[name] = acc\n",
    "\n",
    "    print(f\"\\n {name}\")\n",
    "    print(\"Accuracy:\", round(acc, 4))\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17a76f8-2075-48d4-a196-92459ee36063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Define stratified k-fold cross-validator\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store cross-validation results\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_scaled, y_encoded, cv=skf, scoring='accuracy')\n",
    "    cv_results[name] = scores.mean()\n",
    "    print(f\"ðŸ”¸ {name}:\")\n",
    "    print(\"  Mean Accuracy:\", round(scores.mean(), 4))\n",
    "    print(\"  Std Deviation:\", round(scores.std(), 4))\n",
    "    print(\"  All Fold Scores:\", np.round(scores, 4), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ee270-c321-42af-8c95-ab8e339b77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(x=y, palette=\"viridis\")\n",
    "plt.title(\"Original Class Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102dd6d7-cc9a-4cca-819c-68135081ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y_encoded)\n",
    "\n",
    "print(\"After SMOTE:\", dict(pd.Series(y_resampled).value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd10b8-2780-4c12-8e26-fbb8356014f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_scaled, y_encoded)\n",
    "\n",
    "print(\"After Random Undersampling:\", dict(pd.Series(y_rus).value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc9f24-1991-47da-b6bf-ecc292b9caa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613f05f-4c20-4297-ac73-0c6061386ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16898b70-9a81-4c68-80ac-c7c1fcd3846b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b78da-b656-43fe-9dce-b28cd9abce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                       param_grid=param_grid_rf,\n",
    "                       cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for Random Forest:\")\n",
    "print(grid_rf.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", round(grid_rf.best_score_, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219db32b-8820-4c25-a590-12d23ef965f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "param_dist_svm = {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "random_svm = RandomizedSearchCV(SVC(),\n",
    "                                param_distributions=param_dist_svm,\n",
    "                                n_iter=10,\n",
    "                                cv=5,\n",
    "                                scoring='accuracy',\n",
    "                                random_state=42,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "random_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters for SVM:\")\n",
    "print(random_svm.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", round(random_svm.best_score_, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f75d90-fa76-491d-9265-2446fc3ee08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize list\n",
    "comparison_table = []\n",
    "\n",
    "# Re-train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    overfit = 'Yes' if (train_acc - test_acc) > 0.05 else 'No'\n",
    "\n",
    "    comparison_table.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': round(train_acc, 4),\n",
    "        'Test Accuracy': round(test_acc, 4),\n",
    "        'F1 Score': round(f1, 4),\n",
    "        'Overfitting': overfit\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "import pandas as pd\n",
    "comparison_df = pd.DataFrame(comparison_table)\n",
    "\n",
    "# Identify best model\n",
    "best_model = comparison_df.loc[comparison_df['F1 Score'].idxmax()]\n",
    "comparison_df.loc[len(comparison_df.index)] = [\n",
    "    'Best Model: ' + best_model['Model'],\n",
    "    best_model['Train Accuracy'],\n",
    "    best_model['Test Accuracy'],\n",
    "    best_model['F1 Score'],\n",
    "    best_model['Overfitting']\n",
    "]\n",
    "\n",
    "# Display table\n",
    "print(comparison_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57494ab-6b53-46cd-8687-8338ff291203",
   "metadata": {},
   "outputs": [],
   "source": [
    "| Model                         | Train Accuracy | Test Accuracy | F1 Score | Overfitting |\n",
    "| ----------------------------- | -------------- | ------------- | -------- | ----------- |\n",
    "| Logistic Regression           | 0.92           | 0.92          | 0.92     | No          |\n",
    "| Decision Tree                 | 1.00           | 0.89          | 0.89     | **Yes**     |\n",
    "| Random Forest                 | 1.00           | 0.91          | 0.91     | No          |\n",
    "| SVM                           | 0.93           | 0.92          | 0.92     | No          |\n",
    "| KNN                           | 0.94           | 0.91          | 0.91     | No          |\n",
    "| Naive Bayes                   | 0.89           | 0.89          | 0.89     | No          |\n",
    "| AdaBoost                      | 0.63           | 0.63          | 0.57     | No          |\n",
    "| Gradient Boosting             | 0.96           | 0.92          | 0.92     | No          |\n",
    "| **Best Model: SVM**           | **0.93**       | **0.92**      | **0.92** | **No**      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b185a5-b72f-4163-bf9d-8d43e8623c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "\n",
    "# For demonstration, we'll train a simple model here (you can remove this in real use)\n",
    "@st.cache_data\n",
    "def train_model():\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    model = SVM()\n",
    "    model.fit(X, y)\n",
    "    return model, iris.feature_names, iris.target_names\n",
    "\n",
    "model, feature_names, class_names = train_model()\n",
    "\n",
    "# --- Streamlit UI ---\n",
    "st.title(\"ðŸ«˜ Bean Classifier App\")\n",
    "st.write(\"Input the features to classify the bean type.\")\n",
    "\n",
    "# Collect user input\n",
    "user_input = []\n",
    "for feature in feature_names:\n",
    "    val = st.number_input(f\"{feature}\", min_value=0.0, value=1.0)\n",
    "    user_input.append(val)\n",
    "\n",
    "# Predict button\n",
    "if st.button(\"Predict Class\"):\n",
    "    input_array = np.array(user_input).reshape(1, -1)\n",
    "    prediction = model.predict(input_array)[0]\n",
    "    st.success(f\"ðŸŒŸ Predicted Class: **{class_names[prediction]}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88229802-5b54-4258-b232-39d961111174",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run bean_classifier_app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551853a-980d-4b1f-8b24-1e5f25d0dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, 'Beans_Multiclass_Classification')\n",
    "joblib.dump(scaler,'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75355630-e2d6-4d9d-b0e0-0696b8540a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537947c-04d3-464a-88ec-1140d2d85d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871fbec-28bf-4924-810d-0cdf1770f116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
